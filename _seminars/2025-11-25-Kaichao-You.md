---
layout: seminar
talk-title: vLLM - Easy, Fast, and Cheap LLM Serving for Everyone
speaker:  Kaichao You
affiliation: UCB
speaker-webpage: https://youkaichao.github.io/research
date: November 25, 2025
day: Tuesday
time: 10:00 am
location: Ryder Hall 156
online: YES
---

**Abstract:**

vLLM is a fast and easy-to-use library for LLM inference and serving. In this talk, I will briefly introduce the evolution of the vLLM project, the open-source community behind it, and highlight some features that are of interest to many users.

**Bio:**

Kaichao You gets a Ph.D. degree from Tsinghua University. He is working on the vLLM project, a high-throughput and memory-efficient inference and serving engine for LLMs. He is also an open-source contributor to PyTorch/Triton.